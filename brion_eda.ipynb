{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae03fdd",
   "metadata": {},
   "source": [
    "\n",
    "# brion_eda.ipynb\n",
    "\n",
    "**BRION ìœ ë°©ì•” ëª¨ë¸ìš© ë°ì´í„° ë¶„ì„/ì‹œê°í™” ë…¸íŠ¸ë¶**\n",
    "\n",
    "- ë³‘ê¸°(Stage) ë° ì•„í˜•(Subtype) ê¸°ì¤€ìœ¼ë¡œ ì•½ì œ ê°œìˆ˜, ê¸‰ì—¬ ì—¬ë¶€ ë“± ì‹œê°í™”\n",
    "- `nccn_breast_stage_drug_map_final_500plus.csv` ê¸°ë°˜ ë¶„ì„\n",
    "- ì£¼ìš” ë¶„ì„: ë³‘ê¸°ë³„ ì•½ì œ ìˆ˜ ë¶„í¬, ê¸‰ì—¬ì—¬ë¶€ ë¹„ìœ¨, ì•„í˜•ë³„ ì¶”ì²œì•½ì œ ìˆ˜ ë“±\n",
    "- matplotlib/seaborn ê¸°ë°˜ ë§‰ëŒ€ê·¸ë˜í”„, pie chart ë“± ì‹œê°í™” í¬í•¨\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ `./data/` ë˜ëŠ” ë™ì¼ ê²½ë¡œì— CSV íŒŒì¼ì´ ìœ„ì¹˜í•´ì•¼ ì‘ë™í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d88197d7-ae78-4734-ba78-3d3c4e1dd888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "import io\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021b135",
   "metadata": {},
   "source": [
    "ì˜ˆì‹œì…ë‹ˆë‹¤: í•„ìš” ì‹œ ë‹¤ë¥¸ txt íŒŒì¼ëª…ì„ ì•„ë˜ì— ì…ë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83183d96-01d0-4426-bed6-8a9e27a76843",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"test_breast_data_varied.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd98ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "except NameError:\n",
    "    # Jupyter Notebookì¼ ê²½ìš° í˜„ì¬ ì›Œí‚¹ ë””ë ‰í† ë¦¬ë¡œ ëŒ€ì²´\n",
    "    base_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f487fd4-6040-49dc-8c16-784b424be41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_safe_eda(df: pd.DataFrame):\n",
    "    print(\"\\U0001F4CC [1] ë°ì´í„° í¬ê¸° ë° ì»¬ëŸ¼ ìˆ˜\")\n",
    "    print(f\"- í–‰(row) ìˆ˜: {df.shape[0]:,}\")\n",
    "    print(f\"- ì—´(column) ìˆ˜: {df.shape[1]:,}\")\n",
    "\n",
    "    print(\"\\n\\U0001F4CC [2] ì»¬ëŸ¼ë³„ ë°ì´í„° íƒ€ì…\")\n",
    "    dtype_df = df.dtypes.reset_index()\n",
    "    dtype_df.columns = ['ì»¬ëŸ¼ëª…', 'ë°ì´í„° íƒ€ì…']\n",
    "    print(dtype_df.to_string(index=False))\n",
    "\n",
    "    print(\"\\n\\U0001F4CC [3] ê²°ì¸¡ì¹˜ ìˆ˜ ë° ë¹„ìœ¨ (ì •ë°€) - null ë¹„ìœ¨ ì†Œìˆ˜ì  4ìë¦¬\")\n",
    "    null_count = df.isnull().sum()\n",
    "    null_percent = (null_count / len(df) * 100).round(4)\n",
    "    null_df = pd.DataFrame({'null_count': null_count, 'null_percent(%)': null_percent})\n",
    "    null_df = null_df.sort_values('null_percent(%)', ascending=False)\n",
    "    print(null_df)\n",
    "\n",
    "    print(\"\\n\\U0001F4CC [4] ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìš”ì•½ í†µê³„ + ì¶”ê°€ ì§€í‘œ\")\n",
    "    if not df.select_dtypes(include=[np.number]).empty:\n",
    "        desc = df.describe(include=[np.number]).T\n",
    "        desc['range'] = desc['max'] - desc['min']\n",
    "        desc['iqr'] = desc['75%'] - desc['25%']\n",
    "        desc['missing'] = df.isnull().sum()\n",
    "        print(desc[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'range', 'iqr', 'missing']].round(4))\n",
    "    else:\n",
    "        print(\"â— ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    print(\"\\n\\U0001F4CC [5] ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬ ìƒìœ„ 5ê°œ\")\n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "    if len(cat_cols) == 0:\n",
    "        print(\"â— ë²”ì£¼í˜• ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        for col in cat_cols:\n",
    "            print(f\"\\n- {col} (ê³ ìœ ê°’ {df[col].nunique()}ê°œ / ì´ {len(df)}í–‰ ì¤‘)\")\n",
    "            print(df[col].value_counts(dropna=False).head(5))\n",
    "\n",
    "    print(\"\\n\\U0001F4CC [6] ë¬¸ìì—´ ê¸¸ì´ í†µê³„ (min/max/mean/median/std/var)\")\n",
    "    for col in cat_cols:\n",
    "        lengths = df[col].dropna().astype(str).apply(len)\n",
    "        if not lengths.empty:\n",
    "            print(f\"- {col}: min={lengths.min()}, max={lengths.max()}, mean={lengths.mean():.2f}, median={lengths.median():.2f}, std={lengths.std():.2f}, var={lengths.var():.2f}\")\n",
    "\n",
    "    print(\"\\n\\U0001F4CC [7] ê° ì»¬ëŸ¼ ê³ ìœ ê°’ 5ê°œ ì˜ˆì‹œ\")\n",
    "    for col in df.columns:\n",
    "        unique_vals = df[col].dropna().unique()\n",
    "        print(f\"- {col} (ê³ ìœ ê°’ {len(unique_vals)}ê°œ): {unique_vals[:5]}\")\n",
    "\n",
    "    print(\"\\n\\U0001F4CC [8] ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ (ìƒìœ„ 10ìŒ + í‰ê·  + ê°•í•œ ê´€ê³„ ë¶„ë¦¬)\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) < 2:\n",
    "        print(\"â— ìƒê´€ê³„ìˆ˜ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        corr_matrix = df[numeric_cols].corr().round(4)\n",
    "        corr_pairs = corr_matrix.unstack()\n",
    "        corr_pairs = corr_pairs[corr_pairs.index.get_level_values(0) != corr_pairs.index.get_level_values(1)]\n",
    "        corr_pairs = corr_pairs.dropna().sort_values(key=abs, ascending=False)\n",
    "        unique_pairs = corr_pairs.groupby(lambda x: frozenset(x)).first()\n",
    "        top_10 = unique_pairs.head(10)\n",
    "        for (var1, var2), val in top_10.items():\n",
    "            print(f\"- {list(var1)[0]} â†” {list(var1)[1]}: ìƒê´€ê³„ìˆ˜ {val:.4f}\")\n",
    "        print(f\"\\n- ì „ì²´ ë³€ìˆ˜ ê°„ ìƒê´€ê³„ìˆ˜ í‰ê· : {unique_pairs.abs().mean():.4f}\")\n",
    "        print(f\"- ì´ ë³€ìˆ˜ ìŒ ìˆ˜: {len(unique_pairs)}\")\n",
    "        strong_pos = unique_pairs[unique_pairs > 0.8]\n",
    "        strong_neg = unique_pairs[unique_pairs < -0.8]\n",
    "        print(f\"- ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„: {len(strong_pos)}ìŒ, ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„: {len(strong_neg)}ìŒ\")\n",
    "\n",
    "    print(\"\\n\\U0001F4CC [9] ì»¬ëŸ¼ëª… íŒ¨í„´ ìë™ ë¶„ë¥˜\")\n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        if 'date' in col_lower:\n",
    "            print(f\"[DATE] {col}\")\n",
    "        elif 'code' in col_lower:\n",
    "            print(f\"[CODE] {col}\")\n",
    "        elif 'flag' in col_lower or 'yn' in col_lower:\n",
    "            print(f\"[FLAG] {col}\")\n",
    "\n",
    "    print(\"\\n\\U0001F4CC [10] ì˜¤ì—¼ëœ íƒ€ì… íƒì§€ (ìˆ«ìí˜•ì¸ë° objectë¡œ ì €ì¥ëœ ì»¬ëŸ¼)\")\n",
    "    found_flag = False\n",
    "    for col in cat_cols:\n",
    "        try:\n",
    "            df[col].astype(float)\n",
    "            print(f\"[ê°€ëŠ¥] '{col}' â†’ float ë³€í™˜ ê°€ëŠ¥ (ìˆ«ìí˜• ì˜¤ì—¼ ê°€ëŠ¥ì„±)\")\n",
    "            found_flag = True\n",
    "        except:\n",
    "            continue\n",
    "    if not found_flag:\n",
    "        print(\"â— ìˆ«ìí˜• ì˜¤ì—¼ëœ object ì»¬ëŸ¼ ì—†ìŒ\")\n",
    "\n",
    "    print(\"\\n\\U0001F4CC [11] í–‰ ê¸°ì¤€ ê²°ì¸¡ì¹˜ í†µê³„ + ë¶„í¬\")\n",
    "    df['nulls_per_row'] = df.isnull().sum(axis=1)\n",
    "    print(df['nulls_per_row'].describe().round(2))\n",
    "    bins = pd.cut(df['nulls_per_row'], bins=[-1, 0, 1, 3, 5, np.inf], labels=['0', '1', '2~3', '4~5', '6+'])\n",
    "    print(\"\\n- ê²°ì¸¡ì¹˜ ê°œìˆ˜ë³„ í–‰ ë¶„í¬:\")\n",
    "    print(bins.value_counts().sort_index())\n",
    "    df.drop(columns=['nulls_per_row'], inplace=True)\n",
    "\n",
    "    print(\"\\n\\U0001F4CC [12] ì»¬ëŸ¼ëª… ìœ ì‚¬ë„ ë¹„êµ (ëª¨ë“  ìŒ ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨, cutoff=0.75 ì´ìƒë§Œ í‘œì‹œ)\")\n",
    "    similarities = []\n",
    "    cols = df.columns.tolist()\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(i+1, len(cols)):\n",
    "            ratio = SequenceMatcher(None, cols[i], cols[j]).ratio()\n",
    "            if ratio >= 0.75:\n",
    "                similarities.append((cols[i], cols[j], ratio))\n",
    "    if similarities:\n",
    "        similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "        for col1, col2, ratio in similarities:\n",
    "            print(f\"- '{col1}' â†” '{col2}' : ìœ ì‚¬ë„ {ratio:.4f}\")\n",
    "        print(f\"\\n- ìœ ì‚¬í•œ ì»¬ëŸ¼ ìŒ ì´ {len(similarities)}ê°œ\")\n",
    "        avg_ratio = np.mean([r[2] for r in similarities])\n",
    "        print(f\"- í‰ê·  ìœ ì‚¬ë„: {avg_ratio:.4f}\")\n",
    "    else:\n",
    "        print(\"â— ìœ ì‚¬í•œ ì»¬ëŸ¼ ìŒì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    print(\"\\n\\U0001F4CC [13] ê³ ìœ ê°’ ê°œìˆ˜ ë§ì€ ë²”ì£¼í˜• ë³€ìˆ˜ (100ê°œ ì´ìƒ)\")\n",
    "    found_many = False\n",
    "    for col in cat_cols:\n",
    "        nunique = df[col].nunique()\n",
    "        if nunique >= 100:\n",
    "            print(f\"- {col}: ê³ ìœ ê°’ {nunique}ê°œ\")\n",
    "            found_many = True\n",
    "        else:\n",
    "            print(f\"- {col}: ê³ ìœ ê°’ {nunique}ê°œ (100 ë¯¸ë§Œ)\")\n",
    "    if not found_many:\n",
    "        print(\"\\nâœ… ì°¸ê³ : í˜„ì¬ ê³ ìœ ê°’ 100ê°œ ì´ìƒì¸ ë²”ì£¼í˜• ë³€ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    print(\"\\nâœ… ê°œì¸ì •ë³´ ì—†ì´ ìµœëŒ€í•œì˜ êµ¬ì¡° ì •ë³´ ì •ë°€ ë¶„ì„ ì™„ë£Œ.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e23a135e-d3a8-4b4f-a7d1-eee6facc850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = io.StringIO()\n",
    "sys.stdout = buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f8d7265-293f-45a6-b3ad-b597e2291d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_safe_eda(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d334f6d-a29d-4060-a9c7-95f9b173a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca2c31b",
   "metadata": {},
   "source": [
    "ì˜ˆì‹œì…ë‹ˆë‹¤: í•„ìš” ì‹œ ë‹¤ë¥¸ txt íŒŒì¼ëª…ì„ ì•„ë˜ì— ì…ë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "213052bc-627a-41bb-bb43-0167ac0207f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"eda_structure2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18c66770-e670-400c-947c-5c08fe8402fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"eda_structure2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a78980f-c65a-4de0-b4fe-251e22f07386",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nğŸ“ ì €ì¥ ì™„ë£Œ: {os.path.abspath('eda_structure2.txt')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (khd_sim)",
   "language": "python",
   "name": "khd_sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
